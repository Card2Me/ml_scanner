#!/usr/bin/env python3
"""
DeepLabV3+ MobileNet ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜ (Softmax ë²„ì „)
2ì±„ë„ ì¶œë ¥ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , Flutterì—ì„œ class 1ë§Œ ì‚¬ìš©
"""
import torch
import torch.nn as nn
from models.deeplabv3_mobilenet import DeepLabV3PlusMobileNet
import argparse

def export_to_onnx(checkpoint_path, output_path, input_size=512):
    """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""

    print(f"âœ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")

    # ëª¨ë¸ ì´ˆê¸°í™” (n_classes=2 ê·¸ëŒ€ë¡œ ìœ ì§€)
    model = DeepLabV3PlusMobileNet(
        n_classes=2,
        encoder_name='mobilenet_v2',
        encoder_weights=None
    )

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    else:
        state_dict = checkpoint

    model.load_state_dict(state_dict)
    model.eval()

    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"  - IoU: {checkpoint.get('best_iou', 'N/A')}")
    print(f"  - Epoch: {checkpoint.get('epoch', 'N/A')}")
    print(f"  - ì¶œë ¥ ì±„ë„: {model.model.segmentation_head[0].out_channels}")

    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    dummy_input = torch.randn(1, 3, input_size, input_size)

    print(f"\nâœ“ ONNX ë³€í™˜ ì‹œì‘...")
    print(f"  - ì…ë ¥ í¬ê¸°: {input_size}x{input_size}")
    print(f"  - ì¶œë ¥ ê²½ë¡œ: {output_path}")
    print(f"  - ì¶œë ¥ í˜•ì‹: 2ì±„ë„ (background, document)")

    # ONNXë¡œ ë³€í™˜ (opset 13ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ for stability)
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=13,  # ì•ˆì •ì„±ì„ ìœ„í•´ 13 ì‚¬ìš©
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        },
        # Legacy exporter ì‚¬ìš©
        dynamo=False
    )

    print(f"âœ“ ONNX ë³€í™˜ ì™„ë£Œ!")

    # ONNX ëª¨ë¸ ê²€ì¦
    print(f"\nâœ“ ONNX ëª¨ë¸ ê²€ì¦ ì¤‘...")
    import onnx
    onnx_model = onnx.load(output_path)
    onnx.checker.check_model(onnx_model)
    print(f"âœ“ ONNX ëª¨ë¸ ê²€ì¦ ì„±ê³µ!")

    # ëª¨ë¸ ì •ë³´
    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"  - ì…ë ¥: {onnx_model.graph.input[0].name}")
    print(f"  - ì…ë ¥ shape: [batch, 3, {input_size}, {input_size}]")
    print(f"  - ì¶œë ¥: {onnx_model.graph.output[0].name}")
    print(f"  - ì¶œë ¥ shape: [batch, 2, {input_size}, {input_size}]")  # 2ì±„ë„

    import os
    file_size = os.path.getsize(output_path) / (1024 * 1024)
    print(f"  - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")

    # ì¶”ë¡  í…ŒìŠ¤íŠ¸
    print(f"\nâœ“ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘...")
    with torch.no_grad():
        pytorch_output = model(dummy_input)  # [1, 2, H, W]

    import onnxruntime as ort
    ort_session = ort.InferenceSession(output_path)
    ort_inputs = {ort_session.get_inputs()[0].name: dummy_input.numpy()}
    onnx_output = ort_session.run(None, ort_inputs)[0]  # [1, 2, H, W]

    # Softmax ì ìš© í›„ class 1 ì„ íƒ
    pytorch_probs = torch.softmax(pytorch_output, dim=1)[:, 1:2]  # class 1 (document)
    onnx_probs_np = np.exp(onnx_output) / np.exp(onnx_output).sum(axis=1, keepdims=True)
    onnx_probs = onnx_probs_np[:, 1:2]  # class 1

    # ë¹„êµ
    diff = np.abs(pytorch_probs.numpy() - onnx_probs).max()
    print(f"âœ“ PyTorch vs ONNX ìµœëŒ€ í™•ë¥  ì°¨ì´: {diff:.6f} ({diff*100:.3f}%)")

    # Binary mask IoU
    pytorch_mask = (pytorch_probs > 0.5).float()
    onnx_mask = (onnx_probs > 0.5).astype(np.float32)

    intersection = (pytorch_mask.numpy() * onnx_mask).sum()
    union = pytorch_mask.sum().item() + onnx_mask.sum() - intersection
    iou = intersection / (union + 1e-8)

    print(f"âœ“ Binary Mask IoU (ì„ê³„ê°’ 0.5): {iou*100:.2f}%")

    if iou > 0.95:
        print(f"\nâœ… ë³€í™˜ ì„±ê³µ! (ë§ˆìŠ¤í¬ IoU > 95%)")
    elif iou > 0.90:
        print(f"\nâœ… ë³€í™˜ ì–‘í˜¸ (ë§ˆìŠ¤í¬ IoU > 90%)")
    else:
        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ (ëœë¤ ì…ë ¥ì´ë¯€ë¡œ IoUê°€ ë‚®ì„ ìˆ˜ ìˆìŒ)")

    print(f"\nğŸ’¡ Flutterì—ì„œ ì‚¬ìš©ë²•:")
    print(f"   1. ëª¨ë¸ ì¶œë ¥: [1, 2, {input_size}, {input_size}]")
    print(f"   2. Softmax ì ìš©: softmax(output, axis=1)")
    print(f"   3. Document í´ë˜ìŠ¤ ì„ íƒ: output[:, 1, :, :]")
    print(f"   4. Binary mask: output > 0.5")

if __name__ == '__main__':
    import numpy as np

    parser = argparse.ArgumentParser(description='PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜ (2ì±„ë„ ë²„ì „)')
    parser.add_argument('--checkpoint', type=str,
                        default='checkpoints/deeplabv3plus_best.pth',
                        help='PyTorch ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--output', type=str,
                        default='checkpoints/deeplabv3plus_mobilenet_2ch.onnx',
                        help='ì¶œë ¥ ONNX íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--input-size', type=int, default=512,
                        help='ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°')

    args = parser.parse_args()

    export_to_onnx(args.checkpoint, args.output, args.input_size)
