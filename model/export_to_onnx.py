#!/usr/bin/env python3
"""
DeepLabV3+ MobileNet ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""
import torch
import torch.nn as nn
from models.deeplabv3_mobilenet import DeepLabV3PlusMobileNet
import argparse

def export_to_onnx(checkpoint_path, output_path, input_size=512):
    """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""

    print(f"âœ“ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")

    # ëª¨ë¸ ì´ˆê¸°í™” (segmentation_models_pytorch ì‚¬ìš©)
    # n_classes=2ë¡œ ë¡œë“œ í›„ ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ 1ë¡œ ë³€ê²½
    model = DeepLabV3PlusMobileNet(
        n_classes=2,
        encoder_name='mobilenet_v2',
        encoder_weights=None  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë“œ
    )

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (weights_only=False for compatibility)
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

    # state_dict ì¶”ì¶œ
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    else:
        state_dict = checkpoint

    model.load_state_dict(state_dict)
    model.eval()

    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    print(f"  - IoU: {checkpoint.get('best_iou', 'N/A')}")
    print(f"  - Epoch: {checkpoint.get('epoch', 'N/A')}")

    # ì¶œë ¥ í—¤ë“œ í™•ì¸
    print(f"  - ì¶œë ¥ ì±„ë„: {model.model.segmentation_head[0].out_channels}")

    # Binary ëª¨ë¸ì„ ìœ„í•´ n_classes=1ë¡œ ë‹¤ì‹œ ìƒì„±
    if model.model.segmentation_head[0].out_channels == 2:
        print(f"\nâœ“ 2ì±„ë„ ëª¨ë¸ì„ 1ì±„ë„(binary)ë¡œ ë³€í™˜ ì¤‘...")

        # class 1 (document)ì˜ ê°€ì¤‘ì¹˜ ì €ì¥
        old_conv = model.model.segmentation_head[0]
        document_weight = old_conv.weight.data[1:2].clone()  # class 1ë§Œ
        document_bias = old_conv.bias.data[1:2].clone()

        # ìƒˆ Conv2d ìƒì„± (1ì±„ë„ ì¶œë ¥)
        new_conv = nn.Conv2d(
            old_conv.in_channels,
            1,
            kernel_size=old_conv.kernel_size,
            padding=old_conv.padding,
            bias=True
        )

        # ê°€ì¤‘ì¹˜ ë³µì‚¬
        with torch.no_grad():
            new_conv.weight.data.copy_(document_weight)
            new_conv.bias.data.copy_(document_bias)

        # êµì²´
        model.model.segmentation_head[0] = new_conv
        model.eval()

        print(f"âœ“ ë³€í™˜ ì™„ë£Œ: ì¶œë ¥ ì±„ë„ {old_conv.out_channels} â†’ 1")

    # ë”ë¯¸ ì…ë ¥ ìƒì„± (NCHW í˜•ì‹)
    dummy_input = torch.randn(1, 3, input_size, input_size)

    print(f"\nâœ“ ONNX ë³€í™˜ ì‹œì‘...")
    print(f"  - ì…ë ¥ í¬ê¸°: {input_size}x{input_size}")
    print(f"  - ì¶œë ¥ ê²½ë¡œ: {output_path}")

    # ONNXë¡œ ë³€í™˜
    torch.onnx.export(
        model,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=18,  # Latest ONNX Runtime compatible version
        do_constant_folding=True,  # ìµœì í™”
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        },
        dynamo=False
    )

    print(f"âœ“ ONNX ë³€í™˜ ì™„ë£Œ!")

    # ONNX ëª¨ë¸ ê²€ì¦
    print(f"\nâœ“ ONNX ëª¨ë¸ ê²€ì¦ ì¤‘...")
    import onnx
    onnx_model = onnx.load(output_path)
    onnx.checker.check_model(onnx_model)
    print(f"âœ“ ONNX ëª¨ë¸ ê²€ì¦ ì„±ê³µ!")

    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"  - ì…ë ¥: {onnx_model.graph.input[0].name}")
    print(f"  - ì…ë ¥ shape: [batch, 3, {input_size}, {input_size}]")
    print(f"  - ì¶œë ¥: {onnx_model.graph.output[0].name}")
    print(f"  - ì¶œë ¥ shape: [batch, 1, {input_size}, {input_size}]")

    # íŒŒì¼ í¬ê¸° ì¶œë ¥
    import os
    file_size = os.path.getsize(output_path) / (1024 * 1024)
    print(f"  - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")

    # ì¶”ë¡  í…ŒìŠ¤íŠ¸
    print(f"\nâœ“ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘...")
    with torch.no_grad():
        pytorch_output = model(dummy_input)

    import onnxruntime as ort
    ort_session = ort.InferenceSession(output_path)
    ort_inputs = {ort_session.get_inputs()[0].name: dummy_input.numpy()}
    ort_output = ort_session.run(None, ort_inputs)[0]

    # ì¶œë ¥ ë¹„êµ
    diff = torch.abs(pytorch_output - torch.from_numpy(ort_output)).max()
    print(f"âœ“ PyTorch vs ONNX ìµœëŒ€ ë¡œì§“ ì°¨ì´: {diff:.6f}")

    # Sigmoid ì ìš© í›„ í™•ë¥  ì°¨ì´ ê³„ì‚°
    pytorch_probs = torch.sigmoid(pytorch_output)
    onnx_probs = torch.sigmoid(torch.from_numpy(ort_output))
    prob_diff = torch.abs(pytorch_probs - onnx_probs).max()

    print(f"âœ“ PyTorch vs ONNX ìµœëŒ€ í™•ë¥  ì°¨ì´: {prob_diff:.6f} ({prob_diff*100:.3f}%)")

    # Binary mask IoU ê³„ì‚° (ì„ê³„ê°’ 0.5)
    pytorch_mask = (pytorch_probs > 0.5).float()
    onnx_mask = (onnx_probs > 0.5).float()

    intersection = (pytorch_mask * onnx_mask).sum()
    union = pytorch_mask.sum() + onnx_mask.sum() - intersection
    iou = (intersection / (union + 1e-8)).item()

    print(f"âœ“ Binary Mask IoU (ì„ê³„ê°’ 0.5): {iou*100:.2f}%")

    if iou > 0.95:
        print(f"âœ“ ë³€í™˜ ì„±ê³µ! (ë§ˆìŠ¤í¬ IoU > 95%)")
    elif iou > 0.90:
        print(f"âœ“ ë³€í™˜ ì–‘í˜¸ (ë§ˆìŠ¤í¬ IoU > 90%)")
    else:
        print(f"âš  ê²½ê³ : ë§ˆìŠ¤í¬ ì°¨ì´ê°€ í¼ (IoU: {iou*100:.2f}%)")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜')
    parser.add_argument('--checkpoint', type=str,
                        default='checkpoints/deeplabv3plus_best.pth',
                        help='PyTorch ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--output', type=str,
                        default='checkpoints/deeplabv3plus_mobilenet.onnx',
                        help='ì¶œë ¥ ONNX íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--input-size', type=int, default=256,
                        help='ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°')

    args = parser.parse_args()

    export_to_onnx(args.checkpoint, args.output, args.input_size)
